# Vendnet #

**Vendnet** is a fork of [Hopenet](https://github.com/natanielruiz/deep-head-pose), which hopes to extend the head pose estimation framework with eye gaze estimation. Vendnet models have been trained on the 300W-LP dataset and have been tested on real data with good qualitative performance. The paper for Hopenet is [here](https://arxiv.org/abs/1710.00925).

Vendnet requires Pytorch and OpenCV.

Pre-trained models:

[300W-LP, alpha 1 (MAE of 6.410)](https://drive.google.com/open?id=1EJPu2sOAwrfuamTitTkw2xJ2ipmMsmD3)

[300W-LP, alpha 2 (MAE of 6.155)](https://drive.google.com/open?id=16OZdRULgUpceMKZV6U9PNFiigfjezsCY)

[300W-LP, alpha 1, robust to image quality](https://drive.google.com/open?id=1m25PrSE7g9D2q2XJVMR6IA7RaCvWSzCR)
